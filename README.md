# AssessAI (formerly NotebookQP)

AssessAI is an AI-powered, RAG-based examination and syllabus assessment workspace. It allows educators to instantly generate comprehensive internal exams, custom quizzes (MCQs and Fill in the Blanks), and unstructured short/long answer questions directly from their own lecture notes, syllabus blueprints, and question banks.

The application leverages **Retrieval-Augmented Generation (RAG)** utilizing `ChromaDB` as the vector engine, and `Groq` (Llama 3.3 70B Versatile) for high-speed, high-quality question framing and cognitive-level (CL/CO) matching.

---

## üöÄ Features

- **Document-Grounded Knowledge Base:** Upload PDFs and TXTs to build an isolated Vector Database for each subject.
- **St. Xavier's Catholic College Exam Format:** By default, it can perfectly generate 50-mark Internal Question papers (Part-A 9x2, Part-B 2x16 with internal OR choices) in strict St. Xavier's formatting.
- **Dynamic Quiz Generator:** Automatically construct multiple-choice quizzes and fill-in-the-bucket sheets (10, 25, or 50 questions) from lecture notes.
- **Freeform Contextual Chat Box:** Chat directly with your syllabus. Ask the AI to summarize units or generate completely custom exam layouts.
- **Print-Ready PDF Exporter:** Cleanly export generated templates to PDF using an integrated `html2pdf.js` engine tuned for paginated CSS.
- **Premium Glassmorphism UI:** A modern, incredibly sleek dark-mode React interface equipped with dynamic mesh gradients and floating glass panels.

---

## üõ†Ô∏è Technology Stack

**Frontend:**
- React (Vite)
- Vanilla CSS (`index.css` for custom mesh gradients and glassmorphism)
- Lucide React (Icons)
- `html2pdf.js` (PDF Generation)

**Backend:**
- FastAPI (Python)
- ChromaDB (Local Vector Storage engine)
- PyPDF2 / langchain-community (Document extraction and splitting)
- Groq Cloud API (`llama-3.3-70b-versatile` for language modeling)

---

## üíª Local Migration & Setup Guide

If you are cloning this repository to run on a new local machine, follow these steps very carefully.

### Prerequisites
- NodeJS (v18+)
- Python (3.10+)
- A [Groq API Key](https://console.groq.com/)

### Step 1: Setting up the FastAPI Backend

1. Open a terminal and navigate to the backend folder:
   ```bash
   cd backend
   ```
2. Create a virtual environment:
   ```bash
   python -m venv .venv
   ```
3. Activate the virtual environment:
   - **Windows:** `.venv\Scripts\activate`
   - **Mac/Linux:** `source .venv/bin/activate`
4. Install the required Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```
   *(Note: Ensure `fastapi`, `uvicorn`, `chromadb`, `langchain`, `langchain-huggingface`, `pypdf2`, and `groq` are installed).*
5. Create your `.env` file! Inside the `backend` folder, create a file named `.env` and add your Groq API Key:
   ```env
   GROQ_API_KEY=gsk_your_api_key_here
   ```
6. Start the server:
   ```bash
   python -m uvicorn main:app --reload --port 8000
   ```
   *The backend should now be running on `http://localhost:8000`.*

### Step 2: Setting up the React Frontend

1. Open a new, separate terminal and navigate to the frontend folder:
   ```bash
   cd frontend
   ```
2. Install the node packages:
   ```bash
   npm install
   ```
3. Start the development server:
   ```bash
   npm run dev
   ```
4. Access the application in your browser at `http://localhost:5173`.

---

## üìÅ System Architecture Notes

- **`/backend/uploads/`**: This directory is automatically generated. It stores the raw `.txt` and `.pdf` files dropped into the frontend based on the Subject.
- **`/backend/chroma_db/`**: This directory is automatically generated by Chroma. It contains the vectorized chunk memory of your uploaded files. If you ever want to completely wipe the AI's "memory", you can delete this folder.
- **`generator.py`**: The central brain. It contains the highly specific prompt engineering required to force the Llama-3 model into generating the strict St. Xavier's templates.

Enjoy generating!
